---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# slmwclf

<!-- badges: start -->
<!-- badges: end -->

Segmented linear model with changeable loss function. 

The goal of slmwclf is to fit for segmented linear model, where not constrained by L2 loss function (as how package 'segmented' does).

Here is a list of situations where this package may be useful:

1. You are confined by a indicator, and different customer applies different explanation of this indicator;
2. Some samples are deviated under a rough criterion, to whom a specially-designed loss may help to resolve;
3. One main/some feature explains most of the effect, and other features count limited weights;
4. Randomly try different loss functions.

## Installation

Package *slmwclf* is in <https://github.com/jwwangars/slmwclf>.

## Example

### One segmented variable operation

This is a basic example which shows you how to solve a common problem within one segmented variable:

```{r example1}
library(slmwclf)
temp = data_generator(1000,55,gen_type = 'chaos&cut')#simulated data
model_1 = SLM_construct(temp[,1],temp[,2],
                        fixed_psi = c(2,6,8,10), loss_function = L2)
print(model_1$y)
predict_model(model_1, c(0,1,10,100,0.5,-1333))
plot(temp[,1],temp[,2]) 
draw_lines_model(model_1,'red')
```

### Multivariable segmented linear network

An extension for one-dimension segmented linear model. In *n*-dimensional space, 
specify cuts for each dimension (see the *cuts* below). With each value of *cuts* setted,
a new point-value can be predicted with weighted average by its 2^n neighbors.

For compatibility of one-dimension, the weights above is chosen to be inverse-proportionally
to the L2-distance between the point and its neighbors:

*\\hat{y} = [\\sum_{i\\in 1:2^n} y_i/d_i]/\\[sum_{i\\in 1:2^n} 1/d_i]*

there the distance *d* derives by Euclid metrics:

*d = \\sqrt{\\sum_{i\\in 1:n}(\\omega_i\\Delta x_i)^2}*

where *\\omega_1 = 1* as the first-dimension metric.

Thus the output contains two parts: point values of *cuts* and distance metrics.

```{r example2}
temp = data_generator(1000,55,gen_type = 'chaos&cut')
y = temp[,2]
one_trial = temp[,-2]
cuts = list(c(-2,4,8,12,21),c(-10,3,16,30),c(0,33,67,100))
tp2_output = msl_network(x = one_trial, y = y, cuts = cuts,
   loss = L1, iter_ctrl = list(iter.max=4, trace = 1))
print(predict_msln(tp2_output,one_trial)[1:5])
plot(y, tp2_output$fitted_values)
lines(c(0,1500),c(0,1500),col='red')
```

### Loss functions

This package contains the following loss functions: L1, L1_shrink, L2, sim_sigmoid_soft.
Note that sim_sigmoid_hard is also a loss function, however sometimes it interrupts iteration, 
please use sim_sigmoid_soft instead.

You can check loss function as:

```{r example3}
sim_sigmoid_soft(1:10,c(3,5))
```

Creating your own loss function within 'SLM_construct':

Suppose the loss function has super-parameter as **a,b,c**, or we say **L(x|a,b,c)**.
Then the new loss function should have 2 input parameters, the first is the independent variable, which here is the error **x**, the second one is ALL of the super-parameter. 

For this particular example, it comes as:

  **L(x) = function(x,c(a,b,c)){other codes ... }**

Just as how *sim_sigmoid_soft* does.

You can use only one input if there is no super-parameter. Like **L(x) = function(x){...}**.

### Other functions

Two other functions in this package do the data-cleansing and calculate the disperse-level:

```{r example4}
temp1 = data_sieve(temp[,1],temp[,2],c(0.7,0.85,500),if_plot = FALSE)
disperse_level(temp[,1],temp[,2])#3.71
disperse_level(temp1$x,temp1$y)#3.51
```

## Update comment

v0.1.1: Function 'SLM_construct' to multivariate input

v0.1.2: Add method of multivariate segmented linear network

v0.1.3: Fix bugs of *SLM_construct* when add 2 variables, and *draw_line_model* setting *minor_fit* to NULL
